{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00GgnvfZOnP3",
        "outputId": "7c9224fd-bc0d-41f4-c62c-b1b75a01931b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto-detected target column: loan_status\n",
            "\n",
            "Standard Random Forest Performance:\n",
            "{\n",
            "  \"0\": {\n",
            "    \"precision\": 0.9244249726177437,\n",
            "    \"recall\": 0.9645714285714285,\n",
            "    \"f1-score\": 0.9440715883668904,\n",
            "    \"support\": 7000.0\n",
            "  },\n",
            "  \"1\": {\n",
            "    \"precision\": 0.8537735849056604,\n",
            "    \"recall\": 0.724,\n",
            "    \"f1-score\": 0.7835497835497836,\n",
            "    \"support\": 2000.0\n",
            "  },\n",
            "  \"accuracy\": 0.9111111111111111,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.889099278761702,\n",
            "    \"recall\": 0.8442857142857143,\n",
            "    \"f1-score\": 0.863810685958337,\n",
            "    \"support\": 9000.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.9087246642372807,\n",
            "    \"recall\": 0.9111111111111111,\n",
            "    \"f1-score\": 0.9084000761853112,\n",
            "    \"support\": 9000.0\n",
            "  }\n",
            "}\n",
            "\n",
            "Standard RF Log Loss: 0.2448\n",
            "\n",
            "Composite-Metric Softmax RF Performance:\n",
            "{\n",
            "  \"0\": {\n",
            "    \"precision\": 0.9267419443679427,\n",
            "    \"recall\": 0.9614285714285714,\n",
            "    \"f1-score\": 0.943766652643388,\n",
            "    \"support\": 7000.0\n",
            "  },\n",
            "  \"1\": {\n",
            "    \"precision\": 0.8446490218642118,\n",
            "    \"recall\": 0.734,\n",
            "    \"f1-score\": 0.7854467629748528,\n",
            "    \"support\": 2000.0\n",
            "  },\n",
            "  \"accuracy\": 0.9108888888888889,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.8856954831160773,\n",
            "    \"recall\": 0.8477142857142856,\n",
            "    \"f1-score\": 0.8646067078091204,\n",
            "    \"support\": 9000.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.9084990727004468,\n",
            "    \"recall\": 0.9108888888888889,\n",
            "    \"f1-score\": 0.9085844549392691,\n",
            "    \"support\": 9000.0\n",
            "  }\n",
            "}\n",
            "\n",
            "Composite Softmax RF Log Loss: 0.2447\n",
            "\n",
            "Composite Scores (first 10 trees): [3.4873 3.4439 3.4618 3.4605 3.4663 3.464  3.4265 3.4432 3.4428 3.4453]\n",
            "Softmax Weights   (first 10 trees): [0.0345 0.033  0.0336 0.0336 0.0338 0.0337 0.0325 0.033  0.033  0.0331]\n",
            "\n",
            "Standard Random Forest Summary:\n",
            "  Accuracy : 0.9111\n",
            "  Precision: 0.9087\n",
            "  Recall   : 0.9111\n",
            "  F1-score : 0.9084\n",
            "  Log-loss : 0.2448\n",
            "\n",
            "Composite-Metric RF (softmax) Summary:\n",
            "  Accuracy : 0.9109\n",
            "  Precision: 0.9085\n",
            "  Recall   : 0.9109\n",
            "  F1-score : 0.9086\n",
            "  Log-loss : 0.2447\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, log_loss\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.special import softmax\n",
        "import json\n",
        "#from ucimlrepo import fetch_ucirepo\n",
        "#spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "# === User configuration ===\n",
        "FILE_PATH = \"/content/loan_data-noise-20.csv\"  # Path to your data file (.csv or .data)\n",
        "TARGET_COLUMN = 'loan_status'          # Name of the target column, or None to auto-detect\n",
        "TEST_SIZE = 0.2                    # Fraction of data to reserve for testing\n",
        "VAL_SIZE = 0.25                    # Fraction of train+val data to reserve for validation\n",
        "N_ESTIMATORS = 30                 # Number of trees in each Random Forest\n",
        "RANDOM_STATE = 42                  # Random seed for reproducibility\n",
        "TEMPERATURE = 1.0                  # Softmax temperature (<1 -> sharper; >1 -> smoother)\n",
        "COMPOSITE_WEIGHTS = [1.0, 1.0, 1.0, 1.0]  # [accuracy, precision, recall, f1]\n",
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load dataset by file extension. Supports .csv and .data as CSVs.\n",
        "    \"\"\"\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext in ['.csv', '.data']:\n",
        "        return pd.read_csv(file_path)\n",
        "    raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "\n",
        "def detect_target_column(df):\n",
        "    \"\"\"\n",
        "    Auto-detect target column: prefers 'target', then 'class', otherwise last column.\n",
        "    \"\"\"\n",
        "    if 'target' in df.columns:\n",
        "        return 'target'\n",
        "    if 'class' in df.columns:\n",
        "        return 'class'\n",
        "    return df.columns[-1]\n",
        "\n",
        "\n",
        "def evaluate_random_forests(df, target_column,\n",
        "                            test_size=TEST_SIZE, val_size=VAL_SIZE,\n",
        "                            n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE,\n",
        "                            temperature=TEMPERATURE, composite_weights=COMPOSITE_WEIGHTS):\n",
        "    \"\"\"\n",
        "    Trains one Random Forest and evaluates:\n",
        "      - Standard RF with majority voting\n",
        "      - Composite-metric weighted RF using multiple metrics per tree\n",
        "    Returns metrics for RF, plus train/test splits, label encoder, and trained RF.\n",
        "    \"\"\"\n",
        "    # Prepare features and labels\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Identify categorical columns for one-hot encoding\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "    numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Create a preprocessor using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', 'passthrough', numerical_cols),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough' # Keep other columns (if any)\n",
        "    )\n",
        "\n",
        "    # Encode string labels to integers\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "\n",
        "    # Split into train+val and test\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y_enc, test_size=test_size, random_state=random_state, stratify=y_enc\n",
        "    )\n",
        "    # Split train and val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=val_size, random_state=random_state, stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Apply preprocessing\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_val_processed = preprocessor.transform(X_val)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "    # Train a single Random Forest\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
        "    rf.fit(X_train_processed, y_train)\n",
        "\n",
        "    # --- Standard evaluation ---\n",
        "    proba_std = rf.predict_proba(X_test_processed)\n",
        "    log_std = log_loss(y_test, proba_std)\n",
        "    y_pred_std = np.argmax(proba_std, axis=1)\n",
        "    metrics_standard = classification_report(\n",
        "        le.inverse_transform(y_test),\n",
        "        le.inverse_transform(y_pred_std),\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    # --- Composite-metric weighting ---\n",
        "    # Compute per-tree metrics on validation set\n",
        "    tree_acc, tree_prec, tree_rec, tree_f1 = [], [], [], []\n",
        "    for tree in rf.estimators_:\n",
        "        # Need to pass processed data to the tree\n",
        "        preds_val = tree.predict(X_val_processed)\n",
        "        tree_acc.append(accuracy_score(y_val, preds_val))\n",
        "        tree_prec.append(precision_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "        tree_rec.append(recall_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "        tree_f1.append(f1_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "    metrics_matrix = np.vstack([tree_acc, tree_prec, tree_rec, tree_f1]).T\n",
        "    composite_scores = metrics_matrix.dot(np.array(composite_weights))\n",
        "    weights = softmax(composite_scores / temperature)\n",
        "\n",
        "    # Aggregate weighted probabilities\n",
        "    proba_weighted = np.zeros_like(proba_std)\n",
        "    for w, tree in zip(weights, rf.estimators_):\n",
        "        # Need to pass processed data to the tree\n",
        "        proba_weighted += w * tree.predict_proba(X_test_processed)\n",
        "    log_weighted = log_loss(y_test, proba_weighted)\n",
        "    y_pred_w = np.argmax(proba_weighted, axis=1)\n",
        "    metrics_weighted = classification_report(\n",
        "        le.inverse_transform(y_test),\n",
        "        le.inverse_transform(y_pred_w),\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    return (metrics_standard, metrics_weighted, log_std, log_weighted,\n",
        "            composite_scores, weights, X_train_processed, y_train, X_test_processed, y_test, le, rf, preprocessor)\n",
        "\n",
        "\n",
        "def print_summary(metrics, title, logloss=None):\n",
        "    \"\"\"\n",
        "    Prints overall accuracy, weighted-average precision, recall, F1, and optional log-loss.\n",
        "    \"\"\"\n",
        "    accuracy = metrics.get('accuracy')\n",
        "    weighted_avg = metrics.get('weighted avg', {})\n",
        "    precision = weighted_avg.get('precision')\n",
        "    recall = weighted_avg.get('recall')\n",
        "    f1 = weighted_avg.get('f1-score')\n",
        "\n",
        "    print(f\"\\n{title} Summary:\")\n",
        "    if accuracy is not None:\n",
        "        print(f\"  Accuracy : {accuracy:.4f}\")\n",
        "    if precision is not None:\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "    if recall is not None:\n",
        "        print(f\"  Recall   : {recall:.4f}\")\n",
        "    if f1 is not None:\n",
        "        print(f\"  F1-score : {f1:.4f}\")\n",
        "    if logloss is not None:\n",
        "        print(f\"  Log-loss : {logloss:.4f}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    df = load_data(FILE_PATH)\n",
        "    target_col = TARGET_COLUMN or detect_target_column(df)\n",
        "    print(f\"Auto-detected target column: {target_col}\\n\")\n",
        "\n",
        "    # Evaluate Random Forests and get splits\n",
        "    (metrics_standard, metrics_weighted,\n",
        "     log_std, log_weighted,\n",
        "     composite_scores, weights,\n",
        "     X_train_processed, y_train, X_test_processed, y_test,\n",
        "     le, rf, preprocessor) = evaluate_random_forests(df, target_col)\n",
        "\n",
        "    # Full reports for RF models\n",
        "    print(\"Standard Random Forest Performance:\")\n",
        "    print(json.dumps(metrics_standard, indent=2))\n",
        "    print(f\"\\nStandard RF Log Loss: {log_std:.4f}\\n\")\n",
        "\n",
        "    print(\"Composite-Metric Softmax RF Performance:\")\n",
        "    print(json.dumps(metrics_weighted, indent=2))\n",
        "    print(f\"\\nComposite Softmax RF Log Loss: {log_weighted:.4f}\\n\")\n",
        "\n",
        "    # Display composite scores and weight distribution\n",
        "    print(f\"Composite Scores (first 10 trees): {np.round(composite_scores[:10], 4)}\")\n",
        "    print(f\"Softmax Weights   (first 10 trees): {np.round(weights[:10], 4)}\")\n",
        "\n",
        "    # Concise summaries including log-loss\n",
        "    print_summary(metrics_standard, \"Standard Random Forest\", log_std)\n",
        "    print_summary(metrics_weighted, \"Composite-Metric RF (softmax)\", log_weighted)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

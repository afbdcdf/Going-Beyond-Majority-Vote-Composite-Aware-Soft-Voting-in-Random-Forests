{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZvD7G3fBnfXE",
        "outputId": "b3b74124-cac1-4457-cb57-17f2520a8534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 'satisfaction' as target column.\n",
            "\n",
            "Standard Random Forest Performance:\n",
            "{\n",
            "  \"neutral or dissatisfied\": {\n",
            "    \"precision\": 0.9569906970473238,\n",
            "    \"recall\": 0.9741302408563782,\n",
            "    \"f1-score\": 0.9654844084741728,\n",
            "    \"support\": 14573.0\n",
            "  },\n",
            "  \"satisfied\": {\n",
            "    \"precision\": 0.9661640639023514,\n",
            "    \"recall\": 0.9440498114531264,\n",
            "    \"f1-score\": 0.9549789310268352,\n",
            "    \"support\": 11403.0\n",
            "  },\n",
            "  \"accuracy\": 0.9609254696643055,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.9615773804748375,\n",
            "    \"recall\": 0.9590900261547524,\n",
            "    \"f1-score\": 0.960231669750504,\n",
            "    \"support\": 25976.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.9610176412361088,\n",
            "    \"recall\": 0.9609254696643055,\n",
            "    \"f1-score\": 0.9608726915303789,\n",
            "    \"support\": 25976.0\n",
            "  }\n",
            "}\n",
            "\n",
            "Standard RF Log Loss: 0.1162\n",
            "\n",
            "Standard RF Summary:\n",
            "  Accuracy : 0.9609\n",
            "  Precision: 0.9610\n",
            "  Recall   : 0.9609\n",
            "  F1-score : 0.9609\n",
            "  Log-loss : 0.1162\n",
            "\n",
            "Composite-Metric Softmax RF Performance:\n",
            "{\n",
            "  \"neutral or dissatisfied\": {\n",
            "    \"precision\": 0.957540164709059,\n",
            "    \"recall\": 0.973375420297811,\n",
            "    \"f1-score\": 0.9653928607887842,\n",
            "    \"support\": 14573.0\n",
            "  },\n",
            "  \"satisfied\": {\n",
            "    \"precision\": 0.9652392044436481,\n",
            "    \"recall\": 0.9448390774357626,\n",
            "    \"f1-score\": 0.9549302016397075,\n",
            "    \"support\": 11403.0\n",
            "  },\n",
            "  \"accuracy\": 0.9608484755158608,\n",
            "  \"macro avg\": {\n",
            "    \"precision\": 0.9613896845763535,\n",
            "    \"recall\": 0.9591072488667868,\n",
            "    \"f1-score\": 0.9601615312142459,\n",
            "    \"support\": 25976.0\n",
            "  },\n",
            "  \"weighted avg\": {\n",
            "    \"precision\": 0.9609199056273496,\n",
            "    \"recall\": 0.9608484755158608,\n",
            "    \"f1-score\": 0.9607999403130788,\n",
            "    \"support\": 25976.0\n",
            "  }\n",
            "}\n",
            "\n",
            "Composite Softmax RF Log Loss: 0.1161\n",
            "\n",
            "Composite-Metric RF (softmax) Summary:\n",
            "  Accuracy : 0.9608\n",
            "  Precision: 0.9609\n",
            "  Recall   : 0.9608\n",
            "  F1-score : 0.9608\n",
            "  Log-loss : 0.1161\n",
            "\n",
            "Composite Scores (first 10 trees): [3.6383 3.6276 3.6499 3.5823 3.6401 3.6293 3.6498 3.6333 3.6566 3.6266]\n",
            "Weights            (first 10 trees): [0.0101 0.01   0.0102 0.0095 0.0101 0.01   0.0102 0.01   0.0103 0.01  ]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-2888365141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-34-2888365141.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mstacked_moe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mproba_moe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_moe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     @available_if(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    255\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    256\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, log_loss\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scipy.special import softmax\n",
        "import json\n",
        "#from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# === User configuration ===\n",
        "TRAIN_PATH = \"\"  # Path to your training data file\n",
        "TEST_PATH  = \"\"   # Path to your test data file\n",
        "TARGET_COLUMN = 'satisfaction'                    # Name of the target column, or None to auto-detect\n",
        "VAL_SIZE = 0.25                            # Fraction of TRAIN data to reserve for validation\n",
        "N_ESTIMATORS = 100                          # Number of trees in each Random Forest\n",
        "RANDOM_STATE = 42                          # Random seed for reproducibility\n",
        "TEMPERATURE = 1.0                          # Softmax temperature (<1 -> sharper; >1 -> smoother)\n",
        "COMPOSITE_WEIGHTS = [1.0, 1.0, 1.0, 1.0]    # [accuracy, precision, recall, f1]\n",
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load dataset by file extension. Supports .csv and .data as CSVs.\n",
        "    \"\"\"\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext in ['.csv', '.data']:\n",
        "        return pd.read_csv(file_path)\n",
        "    raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "\n",
        "def detect_target_column(df):\n",
        "    \"\"\"\n",
        "    Auto-detect target column: prefers 'target', then 'class', otherwise last column.\n",
        "    \"\"\"\n",
        "    if 'target' in df.columns:\n",
        "        return 'target'\n",
        "    if 'class' in df.columns:\n",
        "        return 'class'\n",
        "    return df.columns[-1]\n",
        "\n",
        "\n",
        "def evaluate_random_forests_explicit(df_train, df_test, target_column,\n",
        "                                    val_size=VAL_SIZE, n_estimators=N_ESTIMATORS,\n",
        "                                    random_state=RANDOM_STATE, temperature=TEMPERATURE,\n",
        "                                    composite_weights=COMPOSITE_WEIGHTS):\n",
        "    \"\"\"\n",
        "    Trains one Random Forest on df_train (optionally splitting off validation),\n",
        "    evaluates on df_test, for both standard majority-vote RF and composite-metric softmax RF.\n",
        "    Returns metrics, log-losses, composite scores, weights, processed splits, label encoder, RF, and preprocessor.\n",
        "    \"\"\"\n",
        "    # Split out features & labels\n",
        "    X_train_full = df_train.drop(columns=[target_column])\n",
        "    y_train_full = df_train[target_column]\n",
        "    X_test = df_test.drop(columns=[target_column])\n",
        "    y_test = df_test[target_column]\n",
        "\n",
        "    # Encode labels to integers\n",
        "    le = LabelEncoder()\n",
        "    y_train_enc = le.fit_transform(y_train_full)\n",
        "    y_test_enc  = le.transform(y_test)\n",
        "\n",
        "    # Optionally split train into train + validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_full, y_train_enc, test_size=val_size,\n",
        "        random_state=random_state, stratify=y_train_enc\n",
        "    )\n",
        "\n",
        "    # Identify categorical and numerical columns\n",
        "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "    numerical_cols   = X_train.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Build preprocessing pipeline\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', 'passthrough', numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "    # Fit on train, transform train/val/test\n",
        "    X_train_proc = preprocessor.fit_transform(X_train)\n",
        "    X_val_proc   = preprocessor.transform(X_val)\n",
        "    X_test_proc  = preprocessor.transform(X_test)\n",
        "\n",
        "    # Train a single Random Forest\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
        "    rf.fit(X_train_proc, y_train)\n",
        "\n",
        "    # --- Standard RF evaluation ---\n",
        "    proba_std = rf.predict_proba(X_test_proc)\n",
        "    log_std = log_loss(y_test_enc, proba_std)\n",
        "    y_pred_std = np.argmax(proba_std, axis=1)\n",
        "    metrics_standard = classification_report(\n",
        "        le.inverse_transform(y_test_enc),\n",
        "        le.inverse_transform(y_pred_std),\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    # --- Composite-metric softmax RF ---\n",
        "    # Compute per-tree metrics on validation set\n",
        "    tree_acc, tree_prec, tree_rec, tree_f1 = [], [], [], []\n",
        "    for tree in rf.estimators_:\n",
        "        preds_val = tree.predict(X_val_proc)\n",
        "        tree_acc.append(accuracy_score(y_val, preds_val))\n",
        "        tree_prec.append(precision_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "        tree_rec.append(recall_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "        tree_f1.append(f1_score(y_val, preds_val, average='weighted', zero_division=0))\n",
        "\n",
        "    metrics_matrix = np.vstack([tree_acc, tree_prec, tree_rec, tree_f1]).T\n",
        "    composite_scores = metrics_matrix.dot(np.array(composite_weights))\n",
        "    weights = softmax(composite_scores / temperature)\n",
        "\n",
        "    # Aggregate weighted probabilities\n",
        "    proba_weighted = np.zeros_like(proba_std)\n",
        "    for w, tree in zip(weights, rf.estimators_):\n",
        "        proba_weighted += w * tree.predict_proba(X_test_proc)\n",
        "\n",
        "    log_weighted = log_loss(y_test_enc, proba_weighted)\n",
        "    y_pred_w = np.argmax(proba_weighted, axis=1)\n",
        "    metrics_weighted = classification_report(\n",
        "        le.inverse_transform(y_test_enc),\n",
        "        le.inverse_transform(y_pred_w),\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    return (metrics_standard, metrics_weighted,\n",
        "            log_std, log_weighted,\n",
        "            composite_scores, weights,\n",
        "            X_train_proc, y_train, X_test_proc, y_test_enc,\n",
        "            le, rf, preprocessor)\n",
        "\n",
        "\n",
        "def print_summary(metrics, title, logloss=None):\n",
        "    \"\"\"\n",
        "    Prints overall accuracy, weighted-average precision, recall, F1, and optional log-loss.\n",
        "    \"\"\"\n",
        "    accuracy = metrics.get('accuracy')\n",
        "    weighted = metrics.get('weighted avg', {})\n",
        "    precision = weighted.get('precision')\n",
        "    recall = weighted.get('recall')\n",
        "    f1 = weighted.get('f1-score')\n",
        "\n",
        "    print(f\"\\n{title} Summary:\")\n",
        "    if accuracy is not None:\n",
        "        print(f\"  Accuracy : {accuracy:.4f}\")\n",
        "    if precision is not None:\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "    if recall is not None:\n",
        "        print(f\"  Recall   : {recall:.4f}\")\n",
        "    if f1 is not None:\n",
        "        print(f\"  F1-score : {f1:.4f}\")\n",
        "    if logloss is not None:\n",
        "        print(f\"  Log-loss : {logloss:.4f}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load train and test files\n",
        "    df_train = load_data(TRAIN_PATH)\n",
        "    df_test  = load_data(TEST_PATH)\n",
        "\n",
        "    # Determine target column\n",
        "    target_col = TARGET_COLUMN or detect_target_column(df_train)\n",
        "    print(f\"Using '{target_col}' as target column.\\n\")\n",
        "\n",
        "    # Evaluate Random Forests with explicit train/test\n",
        "    (metrics_std, metrics_w,\n",
        "     log_std, log_w,\n",
        "     comp_scores, weights,\n",
        "     X_train_p, y_train, X_test_p, y_test_enc,\n",
        "     le, rf, preprocessor) = evaluate_random_forests_explicit(\n",
        "         df_train, df_test, target_col\n",
        "    )\n",
        "\n",
        "    # Report standard RF\n",
        "    print(\"Standard Random Forest Performance:\")\n",
        "    print(json.dumps(metrics_std, indent=2))\n",
        "    print(f\"\\nStandard RF Log Loss: {log_std:.4f}\")\n",
        "    print_summary(metrics_std, \"Standard RF\", log_std)\n",
        "\n",
        "    # Report composite-metric RF\n",
        "    print(\"\\nComposite-Metric Softmax RF Performance:\")\n",
        "    print(json.dumps(metrics_w, indent=2))\n",
        "    print(f\"\\nComposite Softmax RF Log Loss: {log_w:.4f}\")\n",
        "    print_summary(metrics_w, \"Composite-Metric RF (softmax)\", log_w)\n",
        "\n",
        "    # Show example composite scores & weights\n",
        "    print(f\"\\nComposite Scores (first 10 trees): {np.round(comp_scores[:10],4)}\")\n",
        "    print(f\"Weights            (first 10 trees): {np.round(weights[:10],4)}\")\n",
        "\n",
        "    # === Stacked MOE Model Evaluation ===\n",
        "    experts = [('rf', rf)]\n",
        "    stacked_moe = StackingClassifier(\n",
        "        estimators=experts,\n",
        "        final_estimator=LogisticRegression(),\n",
        "        cv=5,\n",
        "        stack_method='predict_proba',\n",
        "        passthrough=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    stacked_moe.fit(X_train_p, y_train)\n",
        "\n",
        "    proba_moe = stacked_moe.predict_proba(X_test_p)\n",
        "    log_moe = log_loss(y_test_enc, proba_moe)\n",
        "    y_pred_moe = np.argmax(proba_moe, axis=1)\n",
        "    metrics_moe = classification_report(\n",
        "        le.inverse_transform(y_test_enc),\n",
        "        le.inverse_transform(y_pred_moe),\n",
        "        output_dict=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nStacked MOE Model Performance:\")\n",
        "    print(json.dumps(metrics_moe, indent=2))\n",
        "    print(f\"\\nStacked MOE Model Log Loss: {log_moe:.4f}\")\n",
        "    print_summary(metrics_moe, \"Stacked MOE Model\", log_moe)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
